{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ae2ff79",
   "metadata": {},
   "source": [
    "# RESNET MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a970ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working model - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95701fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "cropped_folder = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/test/test/test_cropped/cropped\"\n",
    "output_folder = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/result/output/\"\n",
    "\n",
    "train_data_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/train/train\"\n",
    "test_data_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/test/test\"\n",
    "\n",
    "validated_images_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/test/test_cropped/validated\"\n",
    "\n",
    "processed_folder = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/result/processed/\"\n",
    "error_folder = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/result/error/\"\n",
    "\n",
    "class_labels_file = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/trained_models/class_labels.pkl\"\n",
    "model_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/trained_models/resnet_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083858a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Learning\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Learning\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Learning\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Execution started...\n",
      "WARNING:tensorflow:From C:\\Users\\Learning\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Learning\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Learning\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "4/4 [==============================] - 3s 348ms/step - loss: 1.5806 - accuracy: 0.7739 - val_loss: 0.6354 - val_accuracy: 0.8966\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.6493 - accuracy: 0.8522 - val_loss: 0.3998 - val_accuracy: 0.8966\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.5144 - accuracy: 0.8609 - val_loss: 0.2584 - val_accuracy: 0.8966\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.4153 - accuracy: 0.8696 - val_loss: 0.1789 - val_accuracy: 0.8966\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.2998 - accuracy: 0.8783 - val_loss: 0.1538 - val_accuracy: 0.8966\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.2580 - accuracy: 0.9130 - val_loss: 0.0863 - val_accuracy: 0.9655\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.2147 - accuracy: 0.9043 - val_loss: 0.0510 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.1459 - accuracy: 0.9739 - val_loss: 0.0566 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.1436 - accuracy: 0.9391 - val_loss: 0.0496 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.0843 - accuracy: 0.9652 - val_loss: 0.0635 - val_accuracy: 0.9655\n",
      "Index to label mapping saved at: C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/trained_models/class_labels.pkl\n",
      "Execution completed.\n",
      "Total execution time: 12.73 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Learning\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define constants\n",
    "training_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/train/train\"\n",
    "trained_model_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/trained_models/\"\n",
    "class_labels_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/trained_models/class_labels.pkl\"\n",
    "\n",
    "# Function to resize an image\n",
    "def resize_image(image, target_width=500):\n",
    "    aspect_ratio = image.shape[1] / image.shape[0]\n",
    "    target_height = int(target_width / aspect_ratio)\n",
    "    resized_image = cv2.resize(image, (target_width, target_height))\n",
    "    return resized_image\n",
    "\n",
    "# Define ResNet model\n",
    "def create_resnet_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    # Define model layers\n",
    "    model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_resnet_model(input_shape, num_classes):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # Add a fully connected layer with softmax activation for classification\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Freeze all layers in the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Dimensions of input images\n",
    "input_shape = (100, 100, 3)\n",
    "# Number of classes\n",
    "num_classes = 18\n",
    "\n",
    "# Build the ResNet model\n",
    "model = build_resnet_model(input_shape, num_classes)\n",
    "\n",
    "def load_images_and_labels(path_dataset, width, height):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    subdirs = [os.path.join(path_dataset, f) for f in os.listdir(path_dataset)]\n",
    "\n",
    "    for subdir in subdirs:\n",
    "        name = subdir.split(os.path.sep)[-1]\n",
    "        images_list = [os.path.join(subdir, f) for f in os.listdir(subdir) if not os.path.basename(f).startswith(\".\")]\n",
    "\n",
    "        for image_path in images_list:\n",
    "            try:\n",
    "                img = cv2.imread(image_path)\n",
    "                if img is None:\n",
    "                    print(\"Error loading image:\", image_path)\n",
    "                    continue\n",
    "\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (width, height))  # Resize image to a fixed size\n",
    "                images.append(img)\n",
    "                labels.append(name)\n",
    "            except Exception as e:\n",
    "                print(\"Error processing image:\", image_path)\n",
    "                print(e)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "def train_resnet_model(images_train, labels_train, images_val, labels_val):\n",
    "    target_width = 100\n",
    "    target_height = 100\n",
    "    images_train_resized = [resize_image(img, target_width) for img in images_train]\n",
    "    images_val_resized = [resize_image(img, target_width) for img in images_val]\n",
    "\n",
    "    input_shape = images_train_resized[0].shape\n",
    "    num_classes = len(np.unique(labels_train))\n",
    "    model = create_resnet_model(input_shape, num_classes)\n",
    "    \n",
    "    label_to_index = {label: i for i, label in enumerate(np.unique(labels_train))}\n",
    "    encoded_labels_train = to_categorical([label_to_index[label] for label in labels_train], num_classes=num_classes)\n",
    "    \n",
    "    # Filter validation set labels to include only those present in the training set\n",
    "    filtered_labels_val = [label for label in labels_val if label in label_to_index]\n",
    "    encoded_labels_val = to_categorical([label_to_index[label] for label in filtered_labels_val], num_classes=num_classes)\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    train_generator = train_datagen.flow(np.array(images_train_resized), encoded_labels_train, batch_size=32)\n",
    "    \n",
    "    # Filter validation images to match filtered labels\n",
    "    filtered_images_val = [image for image, label in zip(images_val_resized, labels_val) if label in label_to_index]\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    val_generator = val_datagen.flow(np.array(filtered_images_val), encoded_labels_val, batch_size=32)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_generator, validation_data=val_generator, epochs=10)\n",
    "    \n",
    "    return model, label_to_index\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Execution started...\")\n",
    "\n",
    "# Load images and labels\n",
    "images, labels = load_images_and_labels(training_path, width=100, height=100)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "images_train, images_val, labels_train, labels_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure that the number of images matches the number of labels\n",
    "assert len(images_train) == len(labels_train)\n",
    "assert len(images_val) == len(labels_val)\n",
    "\n",
    "# Train ResNet model\n",
    "model, index_to_label = train_resnet_model(images_train, labels_train, images_val, labels_val)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(trained_model_path + \"resnet_model.h5\")\n",
    "\n",
    "# Save the index to label mapping\n",
    "with open(class_labels_path, \"wb\") as f:\n",
    "    pickle.dump(index_to_label, f)\n",
    "\n",
    "print(\"Index to label mapping saved at:\", class_labels_path)\n",
    "print(\"Execution completed.\")\n",
    "print(\"Total execution time: {:.2f} seconds\".format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5c8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
