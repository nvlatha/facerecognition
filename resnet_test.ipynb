{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598e8af7",
   "metadata": {},
   "source": [
    "# resent test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "cropped_folder = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/test/test/test_cropped/cropped\"\n",
    "output_folder = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/result/output/\"\n",
    "\n",
    "train_data_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/train/train\"\n",
    "test_data_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/test/test\"\n",
    "\n",
    "validated_images_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/test/test_cropped/validated\"\n",
    "\n",
    "processed_folder = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/result/processed/\"\n",
    "error_folder = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/result/error/\"\n",
    "\n",
    "class_labels_file = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/trained_models/class_labels.pkl\"\n",
    "model_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/trained_models/resnet_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e14936af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model...\n",
      "Execution started...\n",
      "Processing image: a1_1_face.jpg\n",
      "1/1 [==============================] - 0s 473ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9991785883903503\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: a2_1_face.jpg\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.995481014251709\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: ab1_1_face.jpg\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.5707178711891174\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: ab2_1_face.jpg\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.6099060773849487\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: Aishwarya_Rai.34_1_face.jpg\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.972764790058136\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: andrew_test01_1_face.jpg\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9067776203155518\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: DXES7908_1_face.jpg\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9893577694892883\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: DXES7908_2_face.jpg\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.7700191736221313\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG-20230129-WA0013_1_face.jpg\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.8875681161880493\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG-20230129-WA0013_2_face.jpg\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9848061203956604\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG-20230129-WA0020_1_face.jpg\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9499337077140808\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG-20230129-WA0036_1_face.jpg\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.7337594628334045\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG-20230129-WA0036_2_face.jpg\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.7753707766532898\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG-20230129-WA0037_1_face.jpg\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9754201173782349\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: img123_1_face.jpg\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9972143769264221\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1887_1_face.jpg\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.7008130550384521\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1887_2_face.jpg\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9811943173408508\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1887_3_face.jpg\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.8147038817405701\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1887_4_face.jpg\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.6327112317085266\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1887_5_face.jpg\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.8310297727584839\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1887_6_face.jpg\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.8438873291015625\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1887_7_face.jpg\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.988810658454895\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1887_8_face.jpg\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.8219150304794312\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1896_10_face.jpg\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.464401513338089\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1896_11_face.jpg\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9915396571159363\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1896_12_face.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.8485825657844543\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1896_1_face.jpg\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9981170892715454\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1896_2_face.jpg\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.5522093772888184\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1896_3_face.jpg\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.5707093477249146\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1896_4_face.jpg\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.44291892647743225\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1896_5_face.jpg\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.5364747047424316\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1896_6_face.jpg\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.7181643843650818\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1896_7_face.jpg\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.3843430280685425\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1896_8_face.jpg\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.5565944910049438\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1896_9_face.jpg\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9836578965187073\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1995_1_face.jpg\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9590709209442139\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1995_2_face.jpg\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9960587024688721\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1995_3_face.jpg\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.8974214792251587\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1995_4_face.jpg\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9519748091697693\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1995_5_face.jpg\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.5384918451309204\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1995_6_face.jpg\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9872216582298279\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_1995_7_face.jpg\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9358808398246765\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_2014_1_face.jpg\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.5860866904258728\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_2192_1_face.jpg\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.5147238373756409\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_2192_2_face.jpg\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.6664973497390747\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_2192_3_face.jpg\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.6772012114524841\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_3162_1_face.jpg\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9281425476074219\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_3162_2_face.jpg\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.6700806021690369\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_3162_3_face.jpg\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 1\n",
      "Predicted class label: None\n",
      "Confidence score: 0.5196592807769775\n",
      "Error: Predicted class label not found for index 1\n",
      "Processing image: IMG_4227_1_face.jpg\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9612557888031006\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_4227_2_face.jpg\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.99817955493927\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_4227_3_face.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.6352181434631348\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_4227_4_face.jpg\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.4127461910247803\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_4229_1_face.jpg\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9341661334037781\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_4229_2_face.jpg\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9362088441848755\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_4229_3_face.jpg\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 1\n",
      "Predicted class label: None\n",
      "Confidence score: 0.41747233271598816\n",
      "Error: Predicted class label not found for index 1\n",
      "Processing image: IMG_4229_4_face.jpg\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.38367441296577454\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_5130_1_face.jpg\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.6112822890281677\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_5130_2_face.jpg\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9913404583930969\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: IMG_5130_3_face.jpg\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.728224515914917\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: Manoj_3_1_face.jpg\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.47073981165885925\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: Meenal_6_1_face.jpg\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9981263279914856\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: Osama_4_1_face.jpg\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.8429955840110779\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: s1_1_face.jpg\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9995198249816895\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: s2_1_face.jpg\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.8597036004066467\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: sal1_1_face.jpg\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.5821735858917236\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: sal2_1_face.jpg\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.8463110327720642\n",
      "Error: Predicted class label not found for index 0\n",
      "Processing image: Trump_2_1_face.jpg\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Index to label dictionary: {'Aishwarya_Rai': 0, 'Latha NV': 1, 'Meenal': 2, 'Salman_Khan': 3}\n",
      "Predicted class index: 0\n",
      "Predicted class label: None\n",
      "Confidence score: 0.9803881645202637\n",
      "Error: Predicted class label not found for index 0\n",
      "Execution completed.\n",
      "Total execution time: 29.28 seconds\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "import shutil\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "cropped_folder = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/test/test_cropped/\"\n",
    "output_folder = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/result/output/\"\n",
    "\n",
    "train_data_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/train/train\"\n",
    "test_data_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/test/test\"\n",
    "\n",
    "validated_images_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/test/test_cropped/validated\"\n",
    "\n",
    "processed_folder = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/result/processed/\"\n",
    "error_folder = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/result/error/\"\n",
    "\n",
    "class_labels_file = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/trained_models/class_labels.pkl\"\n",
    "model_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/ResNet/dataset/trained_models/resnet_model.h5\"\n",
    "\n",
    "# Define target size for images\n",
    "target_image_size = (100, 100)\n",
    "\n",
    "# Load class labels\n",
    "with open(class_labels_file, \"rb\") as f:\n",
    "    index_to_label = pickle.load(f)\n",
    "\n",
    "# Function to resize an image\n",
    "def resize_image(image, target_width=100, target_height=100):\n",
    "    resized_image = cv2.resize(image, (target_width, target_height))\n",
    "    return resized_image\n",
    "\n",
    "# Function to preprocess an image\n",
    "def preprocess_image(image):\n",
    "    try:\n",
    "        img = resize_image(image)  # Resize the image to target size\n",
    "        img = img / 255.0  # Normalize pixel values\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to crop faces from images\n",
    "def crop_save_image(image_path, output_folder):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is not None:\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        # Process each detected face\n",
    "        for i, (x, y, w, h) in enumerate(faces, 1):\n",
    "            # Draw rectangle around the detected face\n",
    "            cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            # Crop and save the face\n",
    "            face = image[y:y+h, x:x+w]\n",
    "            output_path = os.path.join(output_folder, f\"{os.path.splitext(os.path.basename(image_path))[0]}_{i}_face.jpg\")\n",
    "            cv2.imwrite(output_path, face)\n",
    "\n",
    "# Function to predict the class of an image\n",
    "def predict_image_class(model, image): \n",
    "    try:\n",
    "        preprocessed_img = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "        prediction = model.predict(preprocessed_img)\n",
    "        predicted_class_index = np.argmax(prediction)\n",
    "        confidence_score = prediction[0][predicted_class_index]\n",
    "        \n",
    "        print(\"Index to label dictionary:\", index_to_label)\n",
    "        print(\"Predicted class index:\", predicted_class_index)\n",
    "        \n",
    "        predicted_class_label = index_to_label.get(predicted_class_index)\n",
    "        \n",
    "        print(f\"Predicted class label: {predicted_class_label}\")\n",
    "        print(f\"Confidence score: {confidence_score}\")\n",
    "        \n",
    "        return predicted_class_index, confidence_score  # Return index and confidence score\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting image class: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Function to test the model\n",
    "def test_model(model_path, cropped_folder, output_folder, processed_folder, error_folder, index_to_label):\n",
    "    \n",
    "    print(\"Testing model...\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        print(\"Execution started...\")\n",
    "\n",
    "        # Load the trained model\n",
    "        model = load_model(model_path)\n",
    "    \n",
    "        # Create output directories if they don't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        os.makedirs(processed_folder, exist_ok=True)\n",
    "        os.makedirs(error_folder, exist_ok=True)\n",
    "\n",
    "        # Crop and preprocess images for testing\n",
    "        for filename in os.listdir(test_data_path):\n",
    "            if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                image_path = os.path.join(test_data_path, filename)\n",
    "                crop_save_image(image_path, cropped_folder)\n",
    "\n",
    "        # Process cropped images for testing\n",
    "        for filename in os.listdir(cropped_folder):\n",
    "            print(f\"Processing image: {filename}\")\n",
    "            if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                image_path = os.path.join(cropped_folder, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is not None:\n",
    "                    image = preprocess_image(image)\n",
    "                    if image is not None:\n",
    "                        predicted_class_index, confidence_score = predict_image_class(model, image)\n",
    "                        if predicted_class_index is not None:\n",
    "                            predicted_class_label = index_to_label.get(predicted_class_index)\n",
    "                            if predicted_class_label is not None:\n",
    "                                person_folder = os.path.join(processed_folder, predicted_class_label)\n",
    "                                os.makedirs(person_folder, exist_ok=True)\n",
    "                                shutil.move(image_path, os.path.join(person_folder, filename))\n",
    "                                print(f\"Predicted: {predicted_class_label} with confidence: {confidence_score:.4f} - Image: {filename}\")\n",
    "                            else:\n",
    "                                print(f\"Error: Predicted class label not found for index {predicted_class_index}\")\n",
    "                                shutil.move(image_path, os.path.join(error_folder, filename))\n",
    "                        else:\n",
    "                            print(f\"Error: Unable to predict class for image: {filename}\")\n",
    "                            shutil.move(image_path, os.path.join(error_folder, filename))\n",
    "                    else:\n",
    "                        print(f\"Error: Preprocessing failed for image: {filename}\")\n",
    "                        shutil.move(image_path, os.path.join(error_folder, filename))\n",
    "                else:\n",
    "                    print(f\"Error: Unable to read image: {filename}\")\n",
    "                    shutil.move(image_path, os.path.join(error_folder, filename))\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(\"Execution completed.\")\n",
    "        print(\"Total execution time: {:.2f} seconds\".format(end_time - start_time))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing model: {e}\")\n",
    "\n",
    "# Test the model\n",
    "test_model(model_path, cropped_folder, output_folder, processed_folder, error_folder, index_to_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3aeefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to test and train datasets\n",
    "test_data_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/dataset/test/\"\n",
    "train_data_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/dataset/train/\"\n",
    "\n",
    "# Function to load and display an image with marked faces\n",
    "def load_and_display_image_with_faces(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Load pre-trained face detector\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    # Draw rectangles around the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    \n",
    "    # Display the image with marked faces\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Load and display a test image with marked faces\n",
    "test_image_path = os.path.join(test_data_path, \"IMG_2014.jpg\")\n",
    "print(\"Test Image with Marked Faces:\")\n",
    "load_and_display_image_with_faces(test_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda9015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to test and train datasets\n",
    "test_data_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/dataset/test/\"\n",
    "train_data_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/dataset/train/\"\n",
    "\n",
    "# Load the trained model and class labels\n",
    "model_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/dataset/trained_models/resnet_model.h5\"\n",
    "class_labels_file = \"C:/Users/Learning/udemy/Hackathon/ultimate/dataset/trained_models/class_labels.pkl\"\n",
    "\n",
    "# Load class labels\n",
    "with open(class_labels_file, \"rb\") as f:\n",
    "    index_to_label = pickle.load(f)\n",
    "\n",
    "# Function to crop faces marked with squares and predict their classes\n",
    "def crop_faces_and_predict(image_path, model, index_to_label):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Load pre-trained face detector\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    for i, (x, y, w, h) in enumerate(faces, 1):\n",
    "        # Crop the face region\n",
    "        face = image[y:y+h, x:x+w]\n",
    "        \n",
    "        # Preprocess the cropped face for prediction\n",
    "        preprocessed_face = cv2.resize(face, (100, 100)) / 255.0\n",
    "        cv2.rectangle(preprocessed_face, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "        # Display the image with marked faces\n",
    "        plt.imshow(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        # Expand dimensions to match the input shape of the model\n",
    "        preprocessed_face = np.expand_dims(preprocessed_face, axis=0)\n",
    "        \n",
    "        # Predict the class of the cropped face\n",
    "        prediction = model.predict(preprocessed_face)\n",
    "        predicted_class_index = np.argmax(prediction)\n",
    "        confidence_score = prediction[0][predicted_class_index]\n",
    "        # predicted_class_label = index_to_label[predicted_class_index]\n",
    "        print(\"index\", index_to_label)\n",
    "        \n",
    "        #print(\"===============================================================\")\n",
    "        # Print prediction result\n",
    "        # print(f\"Predicted class label: {predicted_class_label}\")\n",
    "        print(f\"Confidence score: {confidence_score}, Index: {predicted_class_index}\")\n",
    "        \n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Test the function with a test image\n",
    "test_image_path = os.path.join(test_data_path, \"IMG123.jpg\")\n",
    "crop_faces_and_predict(test_image_path, model, index_to_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3562b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Paths to test and train datasets\n",
    "test_data_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/dataset/test/\"\n",
    "train_data_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/dataset/train/\"\n",
    "\n",
    "# Function to encode images\n",
    "def encode_images(data_path):\n",
    "    encoded_images = []\n",
    "    image_names = []\n",
    "\n",
    "    for filename in os.listdir(data_path):\n",
    "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            image_path = os.path.join(data_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                # Encode the image\n",
    "                encoded_image = cv2.imencode('.jpg', image)[1]\n",
    "                encoded_images.append(encoded_image)\n",
    "                image_names.append(filename)\n",
    "    \n",
    "    return encoded_images, image_names\n",
    "\n",
    "# Encode images in train dataset\n",
    "train_encoded_images, train_image_names = encode_images(train_data_path)\n",
    "\n",
    "# Encode images in test dataset\n",
    "test_encoded_images, test_image_names = encode_images(test_data_path)\n",
    "\n",
    "# Print the encodings for train dataset\n",
    "print(\"Train dataset encodings:\")\n",
    "for i, (encoded_image, image_name) in enumerate(zip(train_encoded_images, train_image_names), 1):\n",
    "    print(f\"Image {i}: {encoded_image}\")\n",
    "    print(f\"Image Name: {image_name}\")\n",
    "    print()\n",
    "\n",
    "# Print the encodings for test dataset\n",
    "print(\"Test dataset encodings:\")\n",
    "for i, (encoded_image, image_name) in enumerate(zip(test_encoded_images, test_image_names), 1):\n",
    "    print(f\"Image {i}: {encoded_image}\")\n",
    "    print(f\"Image Name: {image_name}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6592c082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 495ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 421ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 428ms/step\n",
      "1/1 [==============================] - 0s 453ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 817ms/step\n",
      "1/1 [==============================] - 1s 969ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 427ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 470ms/step\n",
      "1/1 [==============================] - 1s 919ms/step\n",
      "1/1 [==============================] - 1s 710ms/step\n",
      "1/1 [==============================] - 1s 856ms/step\n",
      "1/1 [==============================] - 1s 504ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 453ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 1s 504ms/step\n",
      "1/1 [==============================] - 1s 572ms/step\n",
      "1/1 [==============================] - 1s 772ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 517ms/step\n",
      "1/1 [==============================] - 0s 492ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 1s 541ms/step\n",
      "1/1 [==============================] - 1s 727ms/step\n",
      "1/1 [==============================] - 1s 689ms/step\n",
      "1/1 [==============================] - 0s 480ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 453ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 1s 598ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 971ms/step\n",
      "1/1 [==============================] - 1s 556ms/step\n",
      "1/1 [==============================] - 0s 445ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 481ms/step\n",
      "1/1 [==============================] - 0s 458ms/step\n",
      "1/1 [==============================] - 1s 555ms/step\n",
      "1/1 [==============================] - 1s 519ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 1s 843ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 820ms/step\n",
      "1/1 [==============================] - 0s 461ms/step\n",
      "1/1 [==============================] - 1s 535ms/step\n",
      "1/1 [==============================] - 1s 501ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 1s 530ms/step\n",
      "1/1 [==============================] - 1s 544ms/step\n",
      "1/1 [==============================] - 1s 637ms/step\n",
      "1/1 [==============================] - 1s 529ms/step\n",
      "1/1 [==============================] - 1s 778ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 1s 545ms/step\n",
      "1/1 [==============================] - 1s 509ms/step\n",
      "1/1 [==============================] - 1s 593ms/step\n",
      "1/1 [==============================] - 1s 597ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "1/1 [==============================] - 1s 507ms/step\n",
      "1/1 [==============================] - 0s 457ms/step\n",
      "1/1 [==============================] - 0s 445ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 1s 515ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import pickle\n",
    "\n",
    "# Define paths\n",
    "train_data_path = \"C:/Users/Learning/udemy/Hackathon/ultimate/dataset/train/\"\n",
    "\n",
    "# Load pre-trained ResNet model\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add GlobalAveragePooling2D layer to extract features\n",
    "x = resnet_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "feature_extractor = Model(inputs=resnet_model.input, outputs=x)\n",
    "\n",
    "# Function to preprocess and extract features from images using ResNet model\n",
    "def extract_features(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is not None:\n",
    "        # Resize image to fit ResNet input size\n",
    "        resized_image = cv2.resize(image, (224, 224))\n",
    "        # Preprocess input according to ResNet requirements\n",
    "        preprocessed_image = preprocess_input(np.expand_dims(resized_image, axis=0))\n",
    "        # Extract features using ResNet model\n",
    "        features = feature_extractor.predict(preprocessed_image)\n",
    "        return features.flatten()  # Flatten the features\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to encode images in the train dataset using ResNet model\n",
    "def encode_images(data_path):\n",
    "    encodings = []\n",
    "    labels = []\n",
    "\n",
    "    for label in os.listdir(data_path):\n",
    "        label_folder = os.path.join(data_path, label)\n",
    "        if os.path.isdir(label_folder):\n",
    "            for filename in os.listdir(label_folder):\n",
    "                if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                    image_path = os.path.join(label_folder, filename)\n",
    "                    features = extract_features(image_path)\n",
    "                    if features is not None:\n",
    "                        encodings.append(features)\n",
    "                        labels.append(label)\n",
    "    \n",
    "    return encodings, labels\n",
    "\n",
    "# Encode images in the train dataset using ResNet model\n",
    "train_encodings, train_labels = encode_images(train_data_path)\n",
    "\n",
    "# Save the encodings and labels for future use\n",
    "np.save(\"C:/Users/Learning/udemy/Hackathon/ultimate/dataset/trained_models/train_encodings.npy\", train_encodings)\n",
    "np.save(\"C:/Users/Learning/udemy/Hackathon/ultimate/dataset/trained_models/train_labels.npy\", train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "324b1b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step\n",
      "Predicted Label: 6\n",
      "Predicted Label: None\n",
      "Confidence Score: 0.6362315\n",
      "========================================================\n",
      "{'Aishwarya_Rai': 0, 'Akshay_Kumar': 1, 'Alia_Bhatt': 2, 'Asin': 3, 'Barack_Obama': 4, 'Brad_Pitt': 5, 'Deepika_Padukone': 6, 'Donald_Trump': 7, 'George_W_Bush': 8, 'Govinda': 9, 'Latha NV': 10, 'Meenal': 11, 'Rani_Mukerji': 12, 'Salman_Khan': 13, 'Vladimir_Putin': 14}\n",
      "========================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import pickle\n",
    "\n",
    "class_labels_file = \"C:/Users/Learning/udemy/Hackathon/ultimate/dataset/trained_models/class_labels.pkl\"\n",
    "\n",
    "# Load class labels\n",
    "with open(class_labels_file, \"rb\") as f:\n",
    "    index_to_label = pickle.load(f)\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"C:\\\\Users\\\\Learning\\\\udemy\\\\Hackathon\\\\ultimate\\\\dataset\\\\trained_models\\\\resnet_model.h5\")\n",
    "\n",
    "# Load the image\n",
    "image_path = \"C:\\\\Users\\\\Learning\\\\udemy\\\\Hackathon\\\\ultimate\\\\dataset\\\\test\\\\a2.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Preprocess the image (resize, normalize, etc.)\n",
    "# Example resizing to target size (100x100) and normalizing pixel values\n",
    "target_size = (100, 100)\n",
    "preprocessed_image = cv2.resize(image, target_size) / 255.0\n",
    "\n",
    "# Expand dimensions to match the input shape expected by the model\n",
    "preprocessed_image = np.expand_dims(preprocessed_image, axis=0)\n",
    "\n",
    "# Predict the label\n",
    "prediction = model.predict(preprocessed_image)\n",
    "\n",
    "# Convert prediction to label\n",
    "predicted_label_index = np.argmax(prediction)\n",
    " \n",
    "confidence_score = prediction[0][predicted_label_index]\n",
    "\n",
    "# Interpret the prediction\n",
    "#class_labels = [\"class_0\", \"class_1\", \"class_2\", ...]  # Define your class labels\n",
    "predicted_class_label = index_to_label.get(predicted_label_index)\n",
    "\n",
    "print(\"Predicted Label:\", predicted_label_index)\n",
    "print(\"Predicted Label:\", predicted_class_label)\n",
    "print(\"Confidence Score:\", confidence_score)\n",
    "print(\"========================================================\")\n",
    "\n",
    "print(index_to_label)\n",
    "\n",
    "print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f091138",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer count mismatch when loading weights from file. Model expected 106 layers, found 4 saved layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mbase_model\u001b[38;5;241m.\u001b[39minput, outputs\u001b[38;5;241m=\u001b[39mx)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Load the weights of the trained model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLearning\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mudemy\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mHackathon\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124multimate\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtrained_models\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mresnet_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Load the image\u001b[39;00m\n\u001b[0;32m     28\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLearning\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mudemy\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mHackathon\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124multimate\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124ma2.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\legacy\\hdf5_format.py:819\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, model)\u001b[0m\n\u001b[0;32m    817\u001b[0m layer_names \u001b[38;5;241m=\u001b[39m filtered_layer_names\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(filtered_layers):\n\u001b[1;32m--> 819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer count mismatch when loading weights from file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered_layers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layers, found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(layer_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved layers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    823\u001b[0m     )\n\u001b[0;32m    825\u001b[0m \u001b[38;5;66;03m# We batch weight value assignments in a single backend call\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;66;03m# which provides a speedup in TensorFlow.\u001b[39;00m\n\u001b[0;32m    827\u001b[0m weight_value_tuples \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 106 layers, found 4 saved layers."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import pickle\n",
    "\n",
    "class_labels_file = \"C:/Users/Learning/udemy/Hackathon/ultimate/dataset/trained_models/class_labels.pkl\"\n",
    "\n",
    "# Load class labels\n",
    "with open(class_labels_file, \"rb\") as f:\n",
    "    index_to_label = pickle.load(f)\n",
    "\n",
    "# Load ResNet50 model without the top classification layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
    "\n",
    "# Add GlobalAveragePooling2D layer\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Load the weights of the trained model\n",
    "model.load_weights(\"C:\\\\Users\\\\Learning\\\\udemy\\\\Hackathon\\\\ultimate\\\\dataset\\\\trained_models\\\\resnet_model.h5\")\n",
    "\n",
    "# Load the image\n",
    "image_path = \"C:\\\\Users\\\\Learning\\\\udemy\\\\Hackathon\\\\ultimate\\\\dataset\\\\test\\\\a2.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Preprocess the image\n",
    "preprocessed_image = cv2.resize(image, (100, 100))\n",
    "preprocessed_image = preprocess_input(preprocessed_image)\n",
    "\n",
    "# Expand dimensions to match the input shape expected by the model\n",
    "preprocessed_image = np.expand_dims(preprocessed_image, axis=0)\n",
    "\n",
    "# Predict the features\n",
    "features = model.predict(preprocessed_image)\n",
    "\n",
    "# Use the features to make a prediction with your classifier\n",
    "# Your classification code goes here...\n",
    "\n",
    "# You can print the features for debugging if needed\n",
    "print(\"Features:\", features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc63fbac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer count mismatch when loading weights from file. Model expected 106 layers, found 4 saved layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mbase_model\u001b[38;5;241m.\u001b[39minput, outputs\u001b[38;5;241m=\u001b[39mx)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Load the weights of the trained model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLearning\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mudemy\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mHackathon\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124multimate\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtrained_models\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mresnet_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Load the image\u001b[39;00m\n\u001b[0;32m     28\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLearning\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mudemy\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mHackathon\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124multimate\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124ma2.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\legacy\\hdf5_format.py:819\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, model)\u001b[0m\n\u001b[0;32m    817\u001b[0m layer_names \u001b[38;5;241m=\u001b[39m filtered_layer_names\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(filtered_layers):\n\u001b[1;32m--> 819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer count mismatch when loading weights from file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered_layers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layers, found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(layer_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved layers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    823\u001b[0m     )\n\u001b[0;32m    825\u001b[0m \u001b[38;5;66;03m# We batch weight value assignments in a single backend call\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;66;03m# which provides a speedup in TensorFlow.\u001b[39;00m\n\u001b[0;32m    827\u001b[0m weight_value_tuples \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 106 layers, found 4 saved layers."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import pickle\n",
    "\n",
    "class_labels_file = \"C:/Users/Learning/udemy/Hackathon/ultimate/dataset/trained_models/class_labels.pkl\"\n",
    "\n",
    "# Load class labels\n",
    "with open(class_labels_file, \"rb\") as f:\n",
    "    index_to_label = pickle.load(f)\n",
    "\n",
    "# Load ResNet50 model without the top classification layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
    "\n",
    "# Add GlobalAveragePooling2D layer\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Load the weights of the trained model\n",
    "model.load_weights(\"C:\\\\Users\\\\Learning\\\\udemy\\\\Hackathon\\\\ultimate\\\\dataset\\\\trained_models\\\\resnet_model.h5\")\n",
    "\n",
    "# Load the image\n",
    "image_path = \"C:\\\\Users\\\\Learning\\\\udemy\\\\Hackathon\\\\ultimate\\\\dataset\\\\test\\\\a2.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Load the pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'C:\\\\Users\\\\Learning\\\\udemy\\\\Hackathon\\\\ultimate\\\\dataset\\\\trained_models\\\\haarcascade_frontalface_default.xml')\n",
    "\n",
    " \n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the image\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Process each detected face\n",
    "for (x, y, w, h) in faces:\n",
    "    # Draw a rectangle around the detected face\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the image with the square around the face\n",
    "    cv2.imshow(\"Face Detection\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Crop the face from the image\n",
    "    face = image[y:y+h, x:x+w]\n",
    "\n",
    "    # Save the cropped face image\n",
    "    cv2.imwrite(\"C:\\\\Users\\\\Learning\\\\udemy\\\\Hackathon\\\\ultimate\\\\dataset\\\\test\\\\cropped_face.jpg\", face)\n",
    "\n",
    "# Perform validation or further processing on the cropped face image\n",
    "image = cv2.imread(\"C:\\\\Users\\\\Learning\\\\udemy\\\\Hackathon\\\\ultimate\\\\dataset\\\\test\\\\cropped_face.jpg\")\n",
    "# Preprocess the image\n",
    "preprocessed_image = cv2.resize(image, (100, 100))\n",
    "preprocessed_image = preprocess_input(preprocessed_image)\n",
    "\n",
    "# Expand dimensions to match the input shape expected by the model\n",
    "preprocessed_image = np.expand_dims(preprocessed_image, axis=0)\n",
    "\n",
    "# Predict the features\n",
    "features = model.predict(preprocessed_image)\n",
    "\n",
    "# Use the features to make a prediction with your classifier\n",
    "# Your classification code goes here...\n",
    "\n",
    "# You can print the features for debugging if needed\n",
    "print(\"Features:\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae2202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
